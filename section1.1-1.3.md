## ðŸ“˜ Theoretical part: Federated Learning and Edge Computing

### 1.1 Edge Computing

Traditional mobile edge computing encompasses a training paradigm where data and computational tasks are selectively distributed across various network layers:

1. **Data Transmission to Edge Servers**: Training data is first transmitted from user-end devices (e.g., smartphones, tablets, and other terminals) to edge servers. Generally, these edge servers are located much closer to the users than cloud servers.
2. **Edge Server Model Training**: The edge servers then use the received data to perform model training tasks. This offloads the training burden from both end devices and cloud servers.
3. **Cloud Server Model Aggregation**: After training, the intermediate models from edge servers are uploaded to the cloud server, which aggregates these models to form a more accurate global model.

This hierarchical computing structure reduces latency and bandwidth costs while protecting user privacy to some extent. However, data transmission from user devices to edge servers still poses potential privacy and security concerns, especially in light of increasingly stringent data protection regulations (e.g., GDPR in the EU, CPBR in the US). Therefore, it is necessary to explore new privacy-preserving training paradigms in edge computing environments.

------

### 1.2 Federated Learning

To address these privacy issues, Google researchers proposed the Federated Learning (FL) paradigm in 2017. This framework allows multiple clients, each with its own local dataset, to collaboratively train a machine learning model by only exchanging model parameters, without sharing raw data. A central server coordinates the training process and ultimately yields a federated model that performs better than any single clientâ€™s locally trained model.

FL abstracts a centralized coordination paradigm where local clients (i.e., edge nodes) store and process data under the control of a central server. This approach relies heavily on emerging **Mobile Edge Computing (MEC)** technologies. Each client node, now referred to as an edge node, must be equipped with storage and computational power. Large-scale distributed tasks can be completed through the collaboration between edge nodes and the cloud server, involving both **local computation** and **global communication**.

As the amount of data generated by modern applications continues to surge, data-driven approaches dominate computing workloads. Thus, machine learning tasks are becoming central to future MEC systems. It is of great research significance to investigate how FL can be integrated into mobile edge environments.

------

### 1.3 Federated Learning and Edge Computing

Although many studies have addressed either Federated Learning or Mobile Edge Computing, most treat them as separate fields.

- In the FL community, some researchers have focused solely on how to categorize FL models that deal with non-IID (non-independent and identically distributed) data .
- Others have highlighted various challenges in FL applications, but few have considered the **resource constraints** faced in mobile edge environments, let alone how to overcome them.
- On the MEC side, some studies vaguely mention FL as a potential technique for edge-based training but lack concrete experimental investigations. For example, works by H. Li and Z. Zhou explore architectures and processes for edge network training and inference but do not deeply engage with the integration of FL into edge environments.